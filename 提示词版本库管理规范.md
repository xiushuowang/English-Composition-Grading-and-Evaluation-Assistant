提示词版本库管理规范
**项目名称：** [大学英语作文打分评测助手]
**文档版本：** [1.0]
**维护者：** [xiushuowang]
**仓库地址：** [xiushuowang/English-Composition-Grading-and-Evaluation-Assistant: ]

------
## 1. 版本库概述

### 1.1 目的
本版本库旨在系统化管理英语作文打分评测助手的所有提示词（Prompts），确保：
•	作文评估标准的统一性和一致性
•	评分逻辑变更的可追溯、可回滚
•	多维度评估提示词的协同管理
•	不同考试标准（四六级/考研/专四专八）的隔离管理
### 1.2 管理原则
•	教育导向：所有提示词以提升学生写作能力为核心目标
•	标准对齐：严格遵循官方考试评分标准
•	渐进优化：基于用户反馈持续改进评估准确性
•	安全边界：严格遵守学术诚信原则

------
2. 目录结构
…
prompts/
├── README.md                 # 版本库说明文档
├── CHANGELOG.md             # 变更日志
├── prompts.yaml             # 提示词主配置文件
├── system/                  # 系统级提示词
│   ├── persona/            # 阅卷角色定义
│   │   ├── v1.0.0.md       # 初始专业阅卷人角色
│   │   ├── v1.1.0.md       # 优化鼓励性沟通风格
│   │   └── current.md -> v1.1.0.md
│   ├── constraints/        # 评估约束和边界
│   │   ├── academic_integrity.md  # 学术诚信约束
│   │   ├── safety_guidelines.md   # 安全指南
│   │   ├── ethical_boundaries.md  # 伦理边界
│   │   └── scoring_standards.md   # 评分标准约束
│   └── workflow/           # 评估工作流程
│       ├── evaluation_pipeline.md # 核心评估流水线
│       ├── error_handling.md     # 异常处理流程
│       └── feedback_generation.md # 反馈生成流程
├── evaluation/             # 评估维度提示词
│   ├── handwriting/        # 字迹卷面评估
│   │   ├── quality_assessment.md
│   │   ├── format_evaluation.md
│   │   └── legibility_scoring.md
│   ├── grammar/           # 语法评估
│   │   ├── error_detection.md
│   │   ├── correction_suggestions.md
│   │   └── advanced_grammar.md
│   ├── vocabulary/        # 词汇评估
│   │   ├── richness_evaluation.md
│   │   ├── usage_appropriateness.md
│   │   └── advanced_vocabulary.md
│   ├── content/           # 内容评估
│   │   ├── relevance_analysis.md
│   │   ├── logic_structure.md
│   │   └── idea_development.md
│   └── structure/         # 结构评估
│       ├── organization_evaluation.md
│       ├── paragraph_coherence.md
│       └── transition_analysis.md
├── exams/                 # 考试标准提示词
│   ├── cet4/             # 英语四级
│   │   ├── scoring_rubric.md
│   │   ├── model_essays.md
│   │   └── common_errors.md
│   ├── cet6/             # 英语六级
│   │   ├── scoring_rubric.md
│   │   ├── model_essays.md
│   │   └── common_errors.md
│   ├── postgraduate/     # 考研英语
│   │   ├── scoring_rubric.md
│   │   ├── model_essays.md
│   │   └── common_errors.md
│   └── tem/              # 专四专八
│       ├── scoring_rubric.md
│       ├── model_essays.md
│       └── common_errors.md
├── tools/                # 工具调用提示词
│   ├── ocr_processing.md    # OCR处理提示词
│   ├── grammar_checker.md   # 语法检查工具
│   ├── content_analyzer.md  # 内容分析工具
│   ├── scoring_calculator.md # 评分计算工具
│   └── model_essay_generator.md # 范文生成工具
├── feedback/             # 反馈生成提示词
│   ├── improvement_suggestions.md # 改进建议
│   ├── encouragement_templates.md # 鼓励性模板
│   ├── level_based_feedback.md   # 分级反馈
│   └── progress_tracking.md      # 进步追踪
├── templates/            # 提示词模板
│   ├── few_shot_template.md      # 少样本模板
│   ├── chain_of_thought.md       # 思维链模板
│   ├── scoring_rubric_template.md # 评分标准模板
│   └── json_output_template.md   # JSON输出模板
├── tests/                # 测试用例和评估
│   ├── test_cases/       # 测试用例
│   │   ├── happy_paths.md        # 正常路径测试
│   │   ├── edge_cases.md         # 边界情况测试
│   │   ├── handwriting_quality.md # 字迹质量测试
│   │   ├── grammar_errors.md     # 语法错误测试
│   │   └── content_evaluation.md # 内容评估测试
│   └── evaluations/      # 评估结果
│       ├── v1.0.0_eval.md
│       ├── v1.1.0_eval.md
│       ├── accuracy_benchmarks.md # 准确性基准测试
│       └── teacher_correlation.md # 与教师评分相关性
├── scripts/              # 辅助脚本
│   ├── validate_prompts.py       # 提示词验证脚本
│   ├── deploy_prompts.py         # 部署脚本
│   ├── cost_calculator.py        # 成本计算脚本
│   ├── accuracy_evaluator.py     # 准确性评估脚本
│   └── performance_monitor.py    # 性能监控脚本
└── docs/                 # 文档资料
    ├── style_guide.md            # 提示词编写规范
    ├── best_practices.md         # 最佳实践
    ├── scoring_standards.md      # 评分标准文档
    └── troubleshooting.md        # 问题排查

…

------
## 3. 核心提示词文件规范

### 3.1 提示词文件格式标准
每个提示词文件应包含以下元数据和使用示例：

# 英语作文多维度评估提示词

**文件：** `evaluation/grammar/error_detection.md`
**版本：** v1.2.0
**创建日期：** 2025-11-03
**最后修改：** 2025-11-03
**修改者：** xiushuowang
**状态：** ✅ 生产环境使用中

## 元数据
```
yaml
prompt_id: "grammar_evaluation_v1"
purpose: "检测英语作文中的语法、拼写和标点错误"
target_model: "gpt-4"
max_tokens: 3000
temperature: 0.1
estimated_cost: 0.03  # 美元/次调用
tags: ["grammar", "error-detection", "correction"]
dependencies:
  - "system/persona/current.md"
  - "system/constraints/scoring_standards.md"
parameters:
  essay_text: "string"
  exam_type: "string"  # CET4/CET6/POSTGRADUATE/TEM
  student_level: "string"  # beginner/intermediate/advanced
…

变更历史
版本	日期	修改内容	修改人	影响评估
v1.0.0	2025-11-03	初始版本	xiushuowang	基础语法检测
v1.1.0	2025-11-03	增加考试类型适配	xiushuowang	提高评分准确性
v1.2.0	2025-11-03	优化错误分类和修正建议	xiushuowang	改善反馈实用性

提示词内容
…
你是一个专业的英语语法评估专家。你的任务是检测学生英语作文中的语法错误，并提供准确的修正建议。

请按照以下步骤进行分析：

1. 识别语法错误（时态、语态、主谓一致等）
2. 检测拼写错误和拼写变体
3. 检查标点符号使用是否正确
4. 根据考试类型（{exam_type}）调整错误严重性判断
5. 为学生水平（{student_level}）提供适当的修正建议

评估标准：
- 严重错误：影响理解的核心语法问题
- 中等错误：局部语法问题但不影响整体理解  
- 轻微错误：拼写、标点等表面问题

作文内容：
{essay_text}

请以JSON格式返回分析结果：
{
  "grammar_score": 0-100,
  "error_categories": {
    "tense_errors": [],
    "subject_verb_agreement": [],
    "article_errors": [],
    "preposition_errors": [],
    "spelling_errors": [],
    "punctuation_errors": []
  },
  "detailed_feedback": [
    {
      "error_type": "string",
      "original": "string", 
      "corrected": "string",
      "position": [start, end],
      "severity": "high/medium/low",
      "explanation": "string"
    }
  ],
  "improvement_suggestions": ["string"]
}
使用示例
输入：
json
{
  "essay_text": "I go to school yesterday and see my teacher. She tell me that the exam will be hold next week.",
  "exam_type": "CET4", 
  "student_level": "beginner"
}
期望输出：
json
{
  "grammar_score": 65,
  "error_categories": {
    "tense_errors": ["go→went", "see→saw"],
    "subject_verb_agreement": ["tell→tells"],
    "voice_errors": ["will be hold→will be held"]
  },
  "detailed_feedback": [
    {
      "error_type": "tense_error",
      "original": "go",
      "corrected": "went",
      "position": [2, 4],
      "severity": "high",
      "explanation": "昨天发生的动作应该使用过去时"
    }
  ],
  "improvement_suggestions": ["注意动词时态的一致性", "练习被动语态的使用"]
}




测试用例
用例1：基础语法错误检测
•	输入： 包含时态和主谓一致错误的作文
•	期望： 准确识别所有错误并提供修正
•	实际结果： ✅ 测试通过 - 检测出5个语法错误
用例2：高级语法结构评估
•	输入： 包含复杂句式的作文
•	期望： 能够评估句子结构复杂性和准确性
•	实际结果： ✅ 测试通过 - 正确分析复合句结构
…

------
## 4. 版本管理策略

### 4.1 版本号规范

使用语义化版本号：`主版本.次版本.修订版本`

- **主版本**：评分标准重大变更或架构重构
- **次版本**：新增评估维度或考试标准
- **修订版本**：评估准确性优化或问题修复

### 4.2 分支策略
…
main分支 - 生产环境使用的稳定版本
develop分支 - 开发中的集成分支
feature/* - 新评估维度或功能开发
release/* - 发布准备分支
hotfix/* - 紧急评分错误修复
…

### 4.3 提交信息规范
…
类型(范围): 描述信息
正文：
•	修改的详细说明
•	准确性影响分析
•	相关测试结果
可选的脚注：
BREAKING CHANGE: 描述不兼容的评分标准变更
示例：
feat(grammar-eval): 增加高级语法结构评估
•	在语法评估中添加复合句分析功能
•	增加虚拟语气、倒装句等高级语法点检测
•	优化错误严重性分级逻辑
测试结果：与教师评分相关性从0.82提升至0.85
关联issue: #45
…

**提交类型说明：**

- `feat`: 新评估维度或功能
- `fix`: 修复评分准确性问题
- `docs`: 评分标准文档更新
- `refactor`: 评估逻辑重构
- `test`: 评估准确性测试
- `perf`: 评估性能优化

------

## 5. 提示词开发工作流

### 5.1 新评估维度开发流程
…
graph TD
A[需求分析] --> B[编写评估提示词]
B --> C[构建测试数据集]
C --> D[准确性验证]
D --> E{准确性达标?}
E -->|是| F[创建特性分支]
E -->|否| B
F --> G[提交Pull Request]
G --> H[团队评审]
H --> I{评审通过?}
I -->|是| J[合并到develop分支]
I -->|否| K[根据反馈修改]
K --> G
J --> L[集成测试]
L --> M{与教师评分相关性>0.8?}
M -->|是| N[合并到main分支]
M -->|否| O[优化评估逻辑]
O --> L
N --> P[部署到对应环境]
…

### 5.2 评估准确性优化流程
…
graph TD
A[收集教师评分数据] --> B[对比分析差异]
B --> C[识别评估偏差]
C --> D[设计优化方案]
D --> E[A/B测试设计]
E --> F[实施优化版本]
F --> G[小范围测试]
G --> H{相关性提升显著?}
H -->|是| I[全量发布]
H -->|否| J[分析原因]
J --> D
I --> K[更新评分标准文档]
K --> A
…

### 5.3 环境配置管理

**不同环境的提示词配置：**

…
# 开发环境配置 (config/development.yaml)
prompts:
  system_persona: "system/persona/v1.1.0.md"
  scoring_standards: "system/constraints/scoring_standards.md"
  model_config:
    base_model: "gpt-4"
    temperature: 0.3
  features:
    enable_experimental_evaluation: true
    detailed_error_analysis: true
  exams:
    default: "CET4"
    enabled: ["CET4", "CET6"]

# 生产环境配置 (config/production.yaml)  
prompts:
  system_persona: "system/persona/v1.0.0.md"
  scoring_standards: "system/constraints/scoring_standards.md"
  model_config:
    base_model: "gpt-4"
    temperature: 0.1
  features:
    enable_experimental_evaluation: false
    detailed_error_analysis: true
  exams:
    default: "CET4"
    enabled: ["CET4", "CET6", "POSTGRADUATE", "TEM"]
…

## 6. 质量保障体系

### 6.1 提示词验证框架
…
# scripts/validate_prompts.py
class EssayPromptValidator:
    def validate_scoring_consistency(self, prompt_content):
        """验证评分标准一致性"""
        # 检查各维度评分权重是否合理
        # 验证评分逻辑是否符合官方标准
        
    def validate_feedback_safety(self, prompt_content):
        """验证反馈安全性"""
        # 检查是否包含鼓励性语言
        # 验证学术诚信约束
        
    def validate_evaluation_coverage(self, prompt_content):
        """验证评估覆盖度"""
        # 检查是否覆盖所有评分维度
        # 验证边界情况处理

def run_essay_validation_suite():
    validator = EssayPromptValidator()
    validator.validate_scoring_consistency(prompt)
    validator.validate_feedback_safety(prompt)
validator.validate_evaluation_coverage(prompt)
…

### 6.2 自动化测试集成
…
# GitHub Actions 配置示例
name: Essay Prompt Validation
on: [push, pull_request]

jobs:
  validate-essay-prompts:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Validate Scoring Standards
        run: python scripts/validate_prompts.py --type scoring
      - name: Run Accuracy Tests
        run: python scripts/accuracy_evaluator.py --dataset test_essays.json
      - name: Teacher Correlation Check
        run: python scripts/teacher_correlation.py --sample-size 100
…

### 6.3 性能监控指标
指标	目标值	监控频率
与教师评分相关性	> 0.85	每周统计
评估响应时间	< 15秒	实时监控
各维度评分一致性	> 90%	每日统计
用户满意度	> 4.2/5.0	每次评估
OCR识别准确率	> 90%	实时监控

------
## 7. 协作与评审流程

### 7.1 Pull Request模板

…
## 作文评估提示词变更说明

### 变更类型
- [ ] 新评估维度
- [ ] 评分标准优化
- [ ] 准确性修复
- [ ] 考试标准更新
- [ ] 反馈生成优化

### 变更描述
[详细描述本次变更的内容和对评估准确性的影响]

### 准确性影响分析
- **受影响维度**：[语法/词汇/内容/结构/卷面]
- **测试数据集**：[使用的测试作文数量]
- **教师评分对比**：[相关性变化]
- **回滚方案**：[描述评分异常时的回滚方案]

### 检查清单
- [ ] 已通过准确性测试
- [ ] 已更新评分标准文档
- [ ] 已验证与官方标准一致性
- [ ] 已进行学术诚信审查

### 相关Issue
[关联的Issue编号]
…

### 7.2 代码评审指南

**评审重点检查项：**
•	评分标准是否符合官方要求？
•	评估逻辑是否考虑边界情况？
•	反馈语言是否鼓励性且教育性强？
•	各维度评分权重是否合理？
•	是否有性能优化空间？

------
## 8. 部署与发布管理

### 8.1 部署脚本示例

…
# scripts/deploy_prompts.py
class EssayPromptDeployer:
    def __init__(self, environment):
        self.environment = environment
        self.config = self.load_config(environment)
    
    def deploy_evaluation_prompts(self, prompt_files):
        """部署评估提示词到目标环境"""
        for prompt_file in prompt_files:
            self.validate_scoring_consistency(prompt_file)
            self.backup_current_version(prompt_file)
            self.deploy_new_version(prompt_file)
            self.verify_evaluation_accuracy(prompt_file)
    
    def rollback_evaluation_prompts(self, prompt_file, version):
        """回滚到指定版本"""
        self.restore_backup(prompt_file, version)
        self.notify_teachers_of_change(version)
…

### 8.2 版本发布清单

**发布前检查：**
•	与教师评分相关性 > 0.8
•	所有考试标准测试通过
•	评分标准文档已更新
•	回滚方案已准备
•	相关教师用户已通知

------
## 9. 附录

### 9.1 常用命令速查

…
# 创建新评估维度分支
git checkout -b feat/new-evaluation-dimension

# 验证评分提示词
python scripts/validate_prompts.py --file prompts/evaluation/grammar/error_detection.md

# 运行准确性测试
python scripts/accuracy_evaluator.py --dataset sample_essays --model gpt-4

# 部署到测试环境
python scripts/deploy_prompts.py --env staging --exam-types CET4,CET6
…

### 9.2 问题排查指南

**常见问题及解决方案：**

1.	评分准确性下降
o	检查评分标准是否与官方一致
o	验证测试数据集覆盖度
o	调整评估维度权重
2.	评估响应时间过长
o	优化提示词长度和结构
o	检查工具调用顺序
o	考虑评估步骤并行化
3.	用户反馈实用性不足
o	检查改进建议的具体性
o	验证鼓励性语言使用
o	优化分级反馈逻辑

### 9.3 提示词编写最佳实践
…
# 作文评估提示词编写指南

## 评分标准一致性
- 严格遵循官方考试评分标准
- 保持各维度评分权重合理
- 确保不同考试类型标准隔离

## 反馈教育价值
- 优先使用鼓励性语言
- 提供具体的改进建议
- 根据学生水平调整反馈深度

## 评估全面性
- 覆盖所有官方评分维度
- 考虑常见错误模式
- 包含边界情况处理
…

------
